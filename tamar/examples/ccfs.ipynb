{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example notebook on how to calculate RVs from CCFs using different line masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/Users/tervin/NEID_Solar_analysis')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import constants\n",
    "from sunpy.net import attrs as a\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "import NEIDcode\n",
    "\n",
    "import tamar.tools.ccf_funcs as ccffuncs\n",
    "from tamar.tools.settings import CsvDir, Config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "File names for saving CCF information (ccf_csv) and csv file\n",
    "with SDO calculations (sdo_csv).\n",
    "\n",
    "Names of mask and fsr mask to use.\n",
    "- specify if the fsr mask needs to be inverted for use"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# csv file to save ccf information\n",
    "ccf_csv = os.path.join(CsvDir.CCFS, 'ccfs.csv')\n",
    "\n",
    "# csv with sdo calculation\n",
    "sdo_csv = os.path.join(CsvDir.NEID_CALC, 'rvs_from_fits.csv')\n",
    "\n",
    "# mask to use\n",
    "mask_name = 'G2_espresso.txt'\n",
    "\n",
    "# fsr mask -- None if no fsr mask\n",
    "fsr_mask = CsvDir.FSR_MASK\n",
    "invert = True  # True if fsr mask is inverted\n",
    "\n",
    "# get list of dates!\n",
    "dates = os.listdir(CsvDir.NEID_SOLAR)  # this is the folder storing the NEID directory structure\n",
    "dates = sorted(dates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configuration parameters.\n",
    "- No updates needed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# configuration parameters\n",
    "config = Config.config\n",
    "\n",
    "# parameters for SDO/HMI image generation\n",
    "time_range = datetime.timedelta(seconds=22)\n",
    "physobs_list = [a.Physobs.los_velocity, a.Physobs.los_magnetic_field, a.Physobs.intensity]\n",
    "\n",
    "# lightspeed\n",
    "LIGHTSPEED = constants.c / 1000  # Speed of light in km/s\n",
    "minzb = -30 / LIGHTSPEED\n",
    "maxzb = +30 / LIGHTSPEED\n",
    "\n",
    "# Set up velocity loop\n",
    "velocity_loop = np.arange(config['velocity_min'], config['velocity_max'], config['velocity_step']) + config['qrv']\n",
    "velsize = len(velocity_loop)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generation of mask object using mask file and config parameters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate mask object based on config parameters\n",
    "mask = NEIDcode.Mask(mask_name, config['mask_half_width'], config['mask_environment'])\n",
    "fsr_mask = fits.getdata(fsr_mask)\n",
    "if invert:\n",
    "    fsr_mask = 1 - fsr_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read in SDO calculations csv\n",
    "df = pd.read_csv(sdo_csv)\n",
    "sdo_dates = df.date_obs.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loop through dates to calculate and save CCF RV information to specified\n",
    "csv file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make lists for saving\n",
    "rv_sun, rv_model, error, ccfs, shift_ccfs, gaussian, rv_gauss, Bobs, v_conv = [], [], [], [], [], [], [], [], []\n",
    "for date in dates:\n",
    "    # get neid files\n",
    "    file = os.path.join(CsvDir.NEID_SOLAR, date, 'level2', date)\n",
    "    files = [i for i in glob.glob(os.path.join(file, '*.fits'))]\n",
    "    nfiles = len(files)\n",
    "    print('Calculating Weighted CCF for', date, 'using', nfiles, 'files.')\n",
    "\n",
    "    # total number of extracted orders\n",
    "    orders = 122  # hard coded for NEID\n",
    "\n",
    "    # setup CCF calculation\n",
    "    ccfs_fortran = np.zeros([nfiles, orders, velsize])\n",
    "    ccfs_pipeline = np.zeros([nfiles, orders, velsize])\n",
    "    rv_order = np.zeros([nfiles, orders])\n",
    "    ccf_weighted = np.zeros([nfiles, velsize])\n",
    "    file_ccfs = np.zeros([nfiles, velsize])\n",
    "\n",
    "    # calculate CCFs and RVs\n",
    "    rv_in_file = []\n",
    "    dvrms = []\n",
    "    for n, f in enumerate(files):\n",
    "        fd = fits.open(f)\n",
    "        flux = fd['SCIFLUX'].data\n",
    "        wave = fd['SCIWAVE'].data\n",
    "        head = fd[0].header\n",
    "        ccfhead = fd['CCFS'].header\n",
    "        ccfwt = np.zeros(122)\n",
    "        main_header = fits.getheader(f)\n",
    "        date_jd = fits.getheader(f)['OBSJD']\n",
    "\n",
    "        if main_header['DRIFTFUN'] == 'simultaneous' and main_header['WAVECAL'] == 'LFCplusThAr':\n",
    "            # get RV and error from SDO calculations\n",
    "            date_obs = date[0:4] + \"-\" + date[4:6].zfill(2) + '-' + date[6:8].zfill(2) + 'T12:00:00'\n",
    "            sdo_inds = np.isin(sdo_dates, date_obs)\n",
    "            rv = df.rv_model_weather_coeff.values[sdo_inds] / 1e3\n",
    "            B = df.Bobs.values[sdo_inds]\n",
    "            vconv = df.v_conv.values[sdo_inds]\n",
    "            # check to even see if we should continue\n",
    "            if len(rv) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                # check that uncertainty is not terrible\n",
    "                if fits.getheader(f, 'CCFS')['DVRMS'] <= .0004:\n",
    "                    # switch between order index and echelle order, then loop\n",
    "                    rv_in_file.append(fits.getheader(f, 'CCFS')['CCFRVMOD'])\n",
    "                    dvrms.append(fits.getheader(f, 'CCFS')['DVRMS'])\n",
    "                    for trueorder in tqdm(range(config['ordmin'], config['ordmax'] + 1, 1)):\n",
    "                        zb = head['SSBZ%03i' % trueorder]\n",
    "                        berv = head['SSBRV%03i' % trueorder]\n",
    "                        raworder = config['bluest_order'] - trueorder\n",
    "                        ccfwt[raworder] = ccfhead['CCFWT%03i' % trueorder]\n",
    "\n",
    "                        # You have to remove NaNs ahead of passing spectrum to Fortran code\n",
    "                        nanfree = NEIDcode.remove_nans(flux[raworder, :], method='linear')\n",
    "                        spectrum = nanfree[0]\n",
    "\n",
    "                        if fsr_mask is None:\n",
    "                            # Number of blaze edge pixels to clip on either side of order\n",
    "                            pix_start = config['clip_edge_pixels']\n",
    "                            pix_end = np.shape(flux)[1] - config['clip_edge_pixels']\n",
    "                        else:\n",
    "                            if np.nansum(np.logical_not(fsr_mask[raworder, :])) == 0:\n",
    "                                print('fsr mask order summed to zero...sad')\n",
    "                                continue\n",
    "                            else:\n",
    "                                pix_start = np.min(np.argwhere(np.logical_not(fsr_mask[raworder, :])))\n",
    "                                pix_end = np.max(np.argwhere(np.logical_not(fsr_mask[raworder, :])))\n",
    "\n",
    "                        dummy_line_start = mask.start * ((1.0 + (velocity_loop[0] / LIGHTSPEED)) / (1.0 + maxzb))\n",
    "                        dummy_line_end = mask.end * ((1.0 + (velocity_loop[-1] / LIGHTSPEED)) / (1.0 + minzb))\n",
    "                        try:\n",
    "                            line_index = np.where((dummy_line_start > np.min(wave[raworder, pix_start:pix_end])) &\n",
    "                                                  (dummy_line_end < np.max(wave[raworder, pix_start:pix_end])))[0]\n",
    "                        except TypeError:\n",
    "                            print('Line index is None...devastating')\n",
    "                            line_index = []\n",
    "\n",
    "                        sn = np.ones(len(flux[raworder, pix_start:pix_end]))\n",
    "                        if not len(line_index) == 0:\n",
    "                            for k in range(len(velocity_loop)):\n",
    "                                ccfs_fortran[n, raworder, k] = NEIDcode.CCF_3d.ccf(mask.start[line_index],\n",
    "                                                                                   mask.end[line_index],\n",
    "                                                                                   wave[raworder, pix_start:pix_end],\n",
    "                                                                                   spectrum[pix_start:pix_end],\n",
    "                                                                                   mask.weight[line_index],\n",
    "                                                                                   sn, velocity_loop[k], berv, 0.)\n",
    "                        else:\n",
    "                            ccfs_fortran[n, raworder, :] = np.zeros(len(velocity_loop))\n",
    "\n",
    "            # check again that we have sdo data\n",
    "            if len(rv) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                # calculate full CCF\n",
    "                ccfsum = np.nansum(ccfs_fortran[n, :, :], axis=0)\n",
    "\n",
    "                # apply weighting scheme to each order to get ccf from each file\n",
    "                ccfmod = np.nansum((ccfs_fortran[n, :, :].T * ccfwt).T, axis=0)\n",
    "                rescale = np.nansum(ccfsum) / np.nansum(ccfmod)\n",
    "                ccfmod *= rescale\n",
    "                file_ccfs[n, :] = ccfmod\n",
    "\n",
    "    # sum up all of the weighted CCFs to make the 'final' CCF\n",
    "    ccf = np.nansum(file_ccfs, axis=0)\n",
    "\n",
    "    # normalize\n",
    "    ccf /= np.nanmax(ccf)\n",
    "\n",
    "    # get gaussian fit\n",
    "    gaussian_fit, g_x, g_y, final_rv = ccffuncs.fit_gaussian_to_ccf(velocity_loop, ccf, config['qrv'],\n",
    "                                                                    config['velocity_half_range_to_fit'])\n",
    "\n",
    "    # add these to lists\n",
    "    rv_model.append(rv)\n",
    "    ccfs.append(ccf)\n",
    "    gaussian.append(gaussian_fit)\n",
    "    rv_gauss.append(final_rv)\n",
    "    Bobs.append(B)\n",
    "    v_conv.append(vconv)\n",
    "    rv_sun.append(np.mean(rv_in_file))\n",
    "    error.append(np.mean(dvrms))\n",
    "\n",
    "    # print calculation complete statement\n",
    "    print('Calculation complete for', date)\n",
    "\n",
    "# create dataframe\n",
    "d = {\n",
    "    'dates': dates,\n",
    "    'rv_model': rv_model,\n",
    "    'rv_error': error,\n",
    "    'rv_sun': rv_sun,\n",
    "    'ccf': ccfs,\n",
    "    'gaussian': gaussian,\n",
    "    'rv_gauss': rv_gauss,\n",
    "    'Bobs': Bobs,\n",
    "    'v_conv': v_conv\n",
    "}\n",
    "\n",
    "# save dataframe to csv using pickle\n",
    "pickle_df = pd.DataFrame(data=d)\n",
    "pickle_df.to_pickle(ccf_csv)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}