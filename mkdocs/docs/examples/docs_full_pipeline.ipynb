{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Outline of correction and velocity calculations from SDO/HMI Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sunpy.map\n",
    "from sunpy.net import Fido\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.coordinates import frames\n",
    "\n",
    "import sdo_hmi_rvs.tools.calculation_funcs as sfuncs\n",
    "import sdo_hmi_rvs.tools.lbc_funcs as lbfuncs\n",
    "import sdo_hmi_rvs.tools.coord_funcs as ctfuncs\n",
    "import sdo_hmi_rvs.tools.utilities as utils\n",
    "from sdo_hmi_rvs.tools.settings import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "User inputted parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# name of csv file to store calculations\n",
    "csv_name = 'csv_name'\n",
    "\n",
    "# date range\n",
    "start_date = datetime.datetime(2021, 8, 21, 0, 00, 0)\n",
    "end_date = datetime.datetime(2021, 8, 23, 0, 00, 0)\n",
    "\n",
    "# query cadence in seconds\n",
    "cadence = 24*3600"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup CSV file and SDO/HMI querying parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create file names\n",
    "csv_file = os.path.join(CsvDir.CALC, csv_name+'.csv')\n",
    "bad_dates_csv = os.path.join(CsvDir.CALC, csv_name+'_bad_dates.csv')\n",
    "\n",
    "# print out csv title\n",
    "print(\"Beginning calculation of values for csv file: \" + csv_name)\n",
    "\n",
    "# List of header strings\n",
    "row_contents = ['date_obs', 'date_jd', 'v_quiet', 'v_disc', 'v_phot', 'v_conv', 'f_bright', 'f_spot', 'f', 'Bobs',\n",
    "                'vphot_bright', 'vphot_spot', 'f_small', 'f_large', 'f_network', 'f_plage', 'f_nonconv',\n",
    "                'quiet_flux', 'ar_flux', 'conv_flux', 'pol_flux', 'pol_conv_flux', 'vconv_quiet', 'vconv_large',\n",
    "                'vconv_small']\n",
    "\n",
    "# Append a list as new line to an old csv file\n",
    "utils.append_list_as_row(csv_file, row_contents)\n",
    "utils.check_dir(CsvDir.CALC)\n",
    "\n",
    "# get hmi data products\n",
    "time_range = datetime.timedelta(seconds=22)\n",
    "physobs_list = [a.Physobs.los_velocity, a.Physobs.los_magnetic_field, a.Physobs.intensity]\n",
    "\n",
    "# get dates list\n",
    "xy = (end_date - start_date).seconds + (end_date - start_date).days * 24 * 3600\n",
    "dates_list = [start_date + datetime.timedelta(seconds=cadence*x) for x in range(0, int(xy/cadence))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Component calculations\n",
    "Run through list to calculate and save values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for i, date in enumerate(dates_list):\n",
    "    # convert the date to a string -- required for use in csv file\n",
    "    date_str, date_obj, date_jd = utils.get_dates(date)\n",
    "\n",
    "    # pull image within specified time range\n",
    "    result = Fido.search(a.Time(str(date_obj - time_range), str(date_obj + time_range)),\n",
    "                         a.Instrument.hmi, physobs_list[0] | physobs_list[1] | physobs_list[2])\n",
    "\n",
    "    # add file to list\n",
    "    file_download = Fido.fetch(result)\n",
    "\n",
    "    # remove unusable file types\n",
    "    good_files = []\n",
    "    for file in file_download:\n",
    "        name, extension = os.path.splitext(file)\n",
    "        if extension == '.fits':\n",
    "            good_files.append(file)\n",
    "\n",
    "    if len(good_files) != 3:\n",
    "        # add the data\n",
    "        # append these values to the csv file\n",
    "        save_vals = [date_str, 'not three good files']\n",
    "        # print that the files are missing\n",
    "        print('\\nNot three good files: ' + date_str + ' index: ' + str(i))\n",
    "\n",
    "        pass\n",
    "    else:\n",
    "        # convert to map sequence\n",
    "        map_seq = sunpy.map.Map(sorted(good_files))\n",
    "\n",
    "        # check for missing data types\n",
    "        missing_map = False\n",
    "        # split into data types\n",
    "        for j, map_obj in enumerate(map_seq):\n",
    "            if map_obj.meta['content'] == 'DOPPLERGRAM':\n",
    "                vmap = map_obj\n",
    "            elif map_obj.meta['content'] == 'MAGNETOGRAM':\n",
    "                mmap = map_obj\n",
    "            elif map_obj.meta['content'] == 'CONTINUUM INTENSITY':\n",
    "                imap = map_obj\n",
    "            else:\n",
    "                missing_map = True\n",
    "\n",
    "        if missing_map:\n",
    "            print(\"Missing a data product for \" + date_str)\n",
    "\n",
    "            # add the data\n",
    "            # append these values to the csv file\n",
    "            save_vals = [date_str, 'missing data product']\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            # coordinate transformation for maps\n",
    "            x, y, pdim, r, d, mu = ctfuncs.coordinates(vmap)\n",
    "            wij, nij, rij = ctfuncs.vel_coords(x, y, pdim, r, vmap)\n",
    "\n",
    "            # remove bad mu values\n",
    "            vmap, mmap, imap = ctfuncs.fix_mu(mu, [vmap, mmap, imap])\n",
    "\n",
    "            # calculate relative positions\n",
    "            deltaw, deltan, deltar, dij = sfuncs.rel_positions(wij, nij, rij, vmap)\n",
    "\n",
    "            # calculate spacecraft velocity\n",
    "            vsc = sfuncs.spacecraft_vel(deltaw, deltan, deltar, dij, vmap)\n",
    "\n",
    "            # optimized solar rotation parameters\n",
    "            a_parameters = [Parameters.a1, Parameters.a2, Parameters.a3]\n",
    "\n",
    "            # calculation of solar rotation velocity\n",
    "            vrot = sfuncs.solar_rot_vel(wij, nij, rij, deltaw, deltan, deltar, dij, vmap, a_parameters)\n",
    "\n",
    "            # calculate corrected velocity\n",
    "            corrected_vel = vmap.data - np.real(vsc) - np.real(vrot)\n",
    "\n",
    "            # corrected velocity maps\n",
    "            map_vel_cor = sfuncs.corrected_map(corrected_vel, vmap, map_type='Corrected-Dopplergram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # limb brightening\n",
    "            Lij = lbfuncs.limb_polynomial(imap)\n",
    "\n",
    "            # calculate corrected data\n",
    "            Iflat = imap.data / Lij\n",
    "\n",
    "            # corrected intensity maps\n",
    "            map_int_cor = sfuncs.corrected_map(Iflat, imap, map_type='Corrected-Intensitygram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # calculate unsigned field strength\n",
    "            Bobs, Br = sfuncs.mag_field(mu, mmap, B_noise=Parameters.B_noise, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            # corrected observed magnetic data map\n",
    "            map_mag_obs = sfuncs.corrected_map(Bobs, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # radial magnetic data map\n",
    "            map_mag_cor = sfuncs.corrected_map(Br, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # calculate magnetic threshold\n",
    "            active, quiet = sfuncs.mag_thresh(mu, mmap, Br_cutoff=Parameters.Br_cutoff, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            # calculate intensity threshold\n",
    "            fac_inds, spot_inds = sfuncs.int_thresh(map_int_cor, active, quiet)\n",
    "\n",
    "            # create threshold array\n",
    "            thresh_arr = sfuncs.thresh_map(fac_inds, spot_inds)\n",
    "\n",
    "            # full threshold maps\n",
    "            map_full_thresh = sfuncs.corrected_map(thresh_arr, mmap, map_type='Threshold',\n",
    "                                                   frame=frames.HeliographicCarrington)\n",
    "\n",
    "            ### velocity contribution due to convective motion of quiet-Sun\n",
    "            v_quiet = sfuncs.v_quiet(map_vel_cor, imap, quiet)\n",
    "\n",
    "            ### velocity contribution due to rotational Doppler imbalance of active regions (faculae/sunspots)\n",
    "            # calculate photospheric velocity\n",
    "            v_phot, vphot_bright, vphot_spot = sfuncs.v_phot(quiet, active, Lij, vrot, imap, mu, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### velocity contribution due to suppression of convective blueshift by active regions\n",
    "            # calculate disc-averaged velocity\n",
    "            v_disc = sfuncs.v_disc(map_vel_cor, imap)\n",
    "\n",
    "            # calculate convective velocity\n",
    "            v_conv = v_disc - v_quiet\n",
    "\n",
    "            ### filling factor\n",
    "            # calculate filling factor\n",
    "            f_bright, f_spot, f = sfuncs.filling_factor(mu, mmap, active, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### unsigned magnetic flux\n",
    "            # unsigned observed flux\n",
    "            unsigned_obs_flux = sfuncs.unsigned_flux(map_mag_obs, imap)\n",
    "\n",
    "            ### calculate the area filling factor\n",
    "            pixA_hem = ctfuncs.pix_area_hem(wij, nij, rij, vmap)\n",
    "            area = sfuncs.area_calc(active, pixA_hem)\n",
    "            f_small, f_large, f_network, f_plage, f_nonconv = sfuncs.area_filling_factor(active, area, mu, mmap,\n",
    "                                                                                         fac_inds, athresh=Parameters.athresh,\n",
    "                                                                                         mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### get the unsigned flux\n",
    "            quiet_flux, ar_flux, conv_flux, pol_flux, pol_conv_flux = sfuncs.area_unsigned_flux(map_mag_obs, imap,\n",
    "                                                                                                    area,\n",
    "                                                                                                    active,\n",
    "                                                                                                athresh=Parameters.athresh)\n",
    "\n",
    "            ### get area weighted convective velocities\n",
    "            vconv_quiet, vconv_large, vconv_small = sfuncs.area_vconv(map_vel_cor, imap, active, area, athresh=Parameters.athresh)\n",
    "\n",
    "            # make array of what we want to save\n",
    "            save_vals = [v_quiet, v_disc, v_phot, v_conv, f_bright, f_spot, f, unsigned_obs_flux, vphot_bright,\n",
    "                         vphot_spot, f_small, f_large, f_network, f_plage, f_nonconv, quiet_flux, ar_flux,\n",
    "                         conv_flux, pol_flux, pol_conv_flux, vconv_quiet, vconv_large, vconv_small]\n",
    "\n",
    "            # round stuff\n",
    "            rounded = np.around(save_vals, 3)\n",
    "            round_vals = [date_str, date_jd]\n",
    "            for val in rounded:\n",
    "                round_vals.append(val)\n",
    "\n",
    "            # append these values to the csv file\n",
    "            utils.append_list_as_row(csv_file, round_vals)\n",
    "\n",
    "            # print that the date is completed\n",
    "            print('\\nCalculations and save to file complete for ' + date_str + ' index: ' + str(i))\n",
    "\n",
    "print('Calculation complete for dates:', start_date, 'to', end_date)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Full RV Calculation\n",
    "\n",
    "Use the photometric and convective velocity components to calculate the full RV."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read in CSV with data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# csv file with rv components\n",
    "csv_file = os.path.join(CsvDir.CALC, 'csv_name.csv')\n",
    "\n",
    "# create pandas dataframe\n",
    "component_df = pd.read_csv(csv_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get velocities lists\n",
    "v_phot = component_df.v_phot.values\n",
    "v_conv = component_df.v_conv.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get scaling factors\n",
    "A = HARPSN.A\n",
    "B = HARPSN.B\n",
    "RV0 = HARPSN.RV0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RV = A*v_phot + B*v_conv + RV0\n",
    "\n",
    "component_df[\"rv_model\"] = RV\n",
    "component_df.to_csv(csv_file, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date_jd = component_df.date_jd.values\n",
    "x = date_jd - date_jd[0]\n",
    "\n",
    "y_list = [component_df.f.values, component_df.Bobs.values, component_df.v_conv.values, component_df.v_phot.values,\n",
    "          component_df.rv_model.values - np.median(component_df.rv_model.values)]\n",
    "xlabel = 'Days since ' + str(int(date_jd[0])) + ' JD'\n",
    "ylabel_list = [r'$\\rm f$' '\\n' r'$\\rm$[%]',\n",
    "               r'$\\rm B_{\\rm obs}$' '\\n' r'$\\rm [G]$',\n",
    "               r'$\\rm v_{\\rm conv}$' '\\n' r'$\\rm[m s^{-1}]$',\n",
    "               r'$\\rm v_{\\rm phot}$' '\\n' r'$\\rm[m s^{-1}]$',\n",
    "               r'$\\rm RV_{\\rm model}$' '\\n' r'$\\rm[m s^{-1}]$']\n",
    "\n",
    "\n",
    "plot_style = os.path.join(PlotDir.MPL, 'figure_series.mplstyle')\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.cal'] = 'Helvetica Neue LT Pro'\n",
    "plt.style.use(plot_style)\n",
    "\n",
    "# set up figure\n",
    "fig, axs = plt.subplots(len(y_list), 1, sharex='all', figsize=[6, 1.5 * len(y_list)],  gridspec_kw={'hspace': 0})\n",
    "\n",
    "# set up axes labels\n",
    "for i in range(0, len(axs)):\n",
    "    axs[i].set(ylabel=ylabel_list[i])\n",
    "    rng = (y_list[i].max() - y_list[i].min())\n",
    "    step = rng/6\n",
    "    ylim = (y_list[i].min() - step, y_list[i].max() + step)\n",
    "    yticks = np.arange(y_list[i].min(), y_list[i].max()+0.0002, step=step*2)\n",
    "    axs[i].set(ylim=ylim, yticks=yticks)\n",
    "\n",
    "axs[i].set(xlabel=xlabel)\n",
    "rng = (x.max() - x.min())\n",
    "step = rng/6\n",
    "xlim = (x.min() - step, x.max() + step)\n",
    "xticks = np.arange(x.min(), x.max()+.001, step=step*2)\n",
    "axs[i].set(xlim=xlim, xticks=xticks)\n",
    "\n",
    "# plot data\n",
    "for i in range(0, len(axs)):\n",
    "    axs[i].scatter(x, y_list[i], color='thistle', s=30, edgecolors='k', linewidths=0.8,\n",
    "                   label='rms: ' + str(np.round(np.std(y_list[i]), 3)))\n",
    "\n",
    "    leg = axs[i].legend(handlelength=0, handletextpad=0, loc='upper left')\n",
    "    for item in leg.legendHandles:\n",
    "        item.set_visible(False)\n",
    "\n",
    "\n",
    "# align y axis labels\n",
    "fig.align_ylabels(axs)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}