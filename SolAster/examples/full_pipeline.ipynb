{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Outline of correction and velocity calculations from SDO/HMI Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sunpy.map\n",
    "from sunpy.net import Fido\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.coordinates import frames\n",
    "\n",
    "import SolAster.tools.rvs as rvs\n",
    "import SolAster.tools.calculation_funcs as sfuncs\n",
    "import SolAster.tools.lbc_funcs as lbfuncs\n",
    "import SolAster.tools.coord_funcs as ctfuncs\n",
    "import SolAster.tools.utilities as utils\n",
    "from SolAster.tools.settings import *\n",
    "from SolAster.tools.plotting_funcs import hmi_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "User inputted parameters. See README or documentation\n",
    "for additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update inputs class\n",
    "class Inputs:\n",
    "    \"\"\"\n",
    "    Class to hold user specified inputs to run examples.\n",
    "    See README or documentation site for additional information.\n",
    "    \"\"\"\n",
    "\n",
    "    # name of csv file to store calculations\n",
    "    csv_name = 'example.csv'\n",
    "\n",
    "    # name of instrument to use for calculation of RV model\n",
    "    # choose either 'NEID' or 'HARPS-N'\n",
    "    inst = 'NEID'\n",
    "\n",
    "    # querying cadence in seconds\n",
    "    cadence = 24 * 60 * 60\n",
    "\n",
    "    # start date for calculationsx\n",
    "    start_date = datetime.datetime(2021, 2, 10, 0, 0, 0)\n",
    "\n",
    "    # end date for calculations\n",
    "    end_date = datetime.datetime(2021, 2, 14, 0, 0, 0)\n",
    "\n",
    "    # True if outputting diagnostic plots\n",
    "    diagnostic_plots = True\n",
    "    # path to save diagnostic figure or none\n",
    "    save_fig = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setup CSV file and SDO/HMI querying parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check input formats\n",
    "start_date, end_date, cadence, csv_name = utils.check_inputs(CsvDir.CALC,  Inputs.start_date,  Inputs.end_date,\n",
    "                                                             Inputs.cadence,  Inputs.csv_name)\n",
    "\n",
    "\n",
    "# print out csv title\n",
    "print(\"Beginning calculation of values for csv file: \" + csv_name)\n",
    "\n",
    "# List of header strings\n",
    "row_contents = ['date_obs', 'date_jd', 'rv_model', 'v_quiet', 'v_disc', 'v_phot', 'v_conv', 'f_bright', 'f_spot', 'f',\n",
    "                'Bobs', 'vphot_bright', 'vphot_spot', 'f_small', 'f_large', 'f_network', 'f_plage',\n",
    "                'quiet_flux', 'ar_flux', 'conv_flux', 'pol_flux', 'pol_conv_flux', 'vconv_quiet', 'vconv_large',\n",
    "                'vconv_small']\n",
    "\n",
    "# create file names\n",
    "csv_file = os.path.join(CsvDir.CALC, csv_name+'.csv')\n",
    "bad_dates_csv = os.path.join(CsvDir.CALC, csv_name+'_bad_dates.csv')\n",
    "utils.append_list_as_row(csv_file, row_contents)\n",
    "\n",
    "\n",
    "# get hmi data products\n",
    "time_range = datetime.timedelta(seconds=22)\n",
    "physobs_list = [a.Physobs.los_velocity, a.Physobs.los_magnetic_field, a.Physobs.intensity]\n",
    "\n",
    "# get dates list\n",
    "xy = (end_date - start_date).seconds + (end_date - start_date).days * 24 * 3600\n",
    "dates_list = [start_date + datetime.timedelta(seconds=cadence*x) for x in range(0, int(xy/cadence))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Component calculations\n",
    "Run through list to calculate and save values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, date in enumerate(dates_list):\n",
    "    # convert the date to a string -- required for use in csv file\n",
    "    date_str, date_obj, date_jd = utils.get_dates(date)\n",
    "\n",
    "    # pull image within specified time range\n",
    "    result = Fido.search(a.Time(str(date_obj - time_range), str(date_obj + time_range)),\n",
    "                         a.Instrument.hmi, physobs_list[0] | physobs_list[1] | physobs_list[2])\n",
    "\n",
    "    # add file to list\n",
    "    file_download = Fido.fetch(result)\n",
    "\n",
    "    # remove unusable file types\n",
    "    good_files = []\n",
    "    for file in file_download:\n",
    "        name, extension = os.path.splitext(file)\n",
    "        if extension == '.fits':\n",
    "            good_files.append(file)\n",
    "\n",
    "    if len(good_files) != 3:\n",
    "        # add the data\n",
    "        # append these values to the csv file\n",
    "        save_vals = [date_str, 'not three good files']\n",
    "        # print that the files are missing\n",
    "        print('\\nNot three good files: ' + date_str + ' index: ' + str(i))\n",
    "\n",
    "        pass\n",
    "    else:\n",
    "        # convert to map sequence\n",
    "        map_seq = sunpy.map.Map(sorted(good_files))\n",
    "\n",
    "        # check for missing data types\n",
    "        missing_map = False\n",
    "        # split into data types\n",
    "        for j, map_obj in enumerate(map_seq):\n",
    "            if map_obj.meta['content'] == 'DOPPLERGRAM':\n",
    "                vmap = map_obj\n",
    "            elif map_obj.meta['content'] == 'MAGNETOGRAM':\n",
    "                mmap = map_obj\n",
    "            elif map_obj.meta['content'] == 'CONTINUUM INTENSITY':\n",
    "                imap = map_obj\n",
    "            else:\n",
    "                missing_map = True\n",
    "\n",
    "        if missing_map:\n",
    "            print(\"Missing a data product for \" + date_str)\n",
    "\n",
    "            # add the data\n",
    "            # append these values to the csv file\n",
    "            save_vals = [date_str, 'missing data product']\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            # coordinate transformation for maps\n",
    "            x, y, pdim, r, d, mu = ctfuncs.coordinates(vmap)\n",
    "            wij, nij, rij = ctfuncs.vel_coords(x, y, pdim, r, vmap)\n",
    "\n",
    "            # remove bad mu values\n",
    "            vmap, mmap, imap = ctfuncs.fix_mu(mu, [vmap, mmap, imap], mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            # calculate relative positions\n",
    "            deltaw, deltan, deltar, dij = sfuncs.rel_positions(wij, nij, rij, vmap)\n",
    "\n",
    "            # calculate spacecraft velocity\n",
    "            vsc = sfuncs.spacecraft_vel(deltaw, deltan, deltar, dij, vmap)\n",
    "\n",
    "            # optimized solar rotation parameters\n",
    "            a_parameters = [Parameters.a1, Parameters.a2, Parameters.a3]\n",
    "\n",
    "            # calculation of solar rotation velocity\n",
    "            vrot = sfuncs.solar_rot_vel(wij, nij, rij, deltaw, deltan, deltar, dij, vmap, a_parameters)\n",
    "\n",
    "            # calculate corrected velocity\n",
    "            corrected_vel = vmap.data - np.real(vsc) - np.real(vrot)\n",
    "\n",
    "            # corrected velocity maps\n",
    "            map_vel_cor = sfuncs.corrected_map(corrected_vel, vmap, map_type='Corrected-Dopplergram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # limb brightening\n",
    "            Lij = lbfuncs.limb_polynomial(imap)\n",
    "\n",
    "            # calculate corrected data\n",
    "            Iflat = imap.data / Lij\n",
    "\n",
    "            # corrected intensity maps\n",
    "            map_int_cor = sfuncs.corrected_map(Iflat, imap, map_type='Corrected-Intensitygram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # calculate unsigned field strength\n",
    "            Bobs, Br = sfuncs.mag_field(mu, mmap, B_noise=Parameters.B_noise, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            # corrected observed magnetic data map\n",
    "            map_mag_obs = sfuncs.corrected_map(Bobs, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # radial magnetic data map\n",
    "            map_mag_cor = sfuncs.corrected_map(Br, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # calculate magnetic threshold\n",
    "            active, quiet = sfuncs.mag_thresh(mu, mmap, Br_cutoff=Parameters.Br_cutoff, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            # calculate intensity threshold\n",
    "            fac_inds, spot_inds = sfuncs.int_thresh(map_int_cor, active, quiet)\n",
    "\n",
    "            # create threshold array\n",
    "            thresh_arr = sfuncs.thresh_map(fac_inds, spot_inds)\n",
    "\n",
    "            # full threshold maps\n",
    "            map_full_thresh = sfuncs.corrected_map(thresh_arr, mmap, map_type='Threshold',\n",
    "                                                   frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # create diagnostic plots\n",
    "            if i == 0 and Inputs.diagnostic_plots == True:\n",
    "                    hmi_plot(map_int_cor, map_mag_cor, map_vel_cor, fac_inds, spot_inds, mu, save_fig=Inputs.save_fig)\n",
    "\n",
    "            ### velocity contribution due to convective motion of quiet-Sun\n",
    "            v_quiet = sfuncs.v_quiet(map_vel_cor, imap, quiet)\n",
    "\n",
    "            ### velocity contribution due to rotational Doppler imbalance of active regions (faculae/sunspots)\n",
    "            # calculate photospheric velocity\n",
    "            v_phot, vphot_bright, vphot_spot = sfuncs.v_phot(quiet, active, Lij, vrot, imap, mu, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### velocity contribution due to suppression of convective blueshift by active regions\n",
    "            # calculate disc-averaged velocity\n",
    "            v_disc = sfuncs.v_disc(map_vel_cor, imap)\n",
    "\n",
    "            # calculate convective velocity\n",
    "            v_conv = v_disc - v_quiet\n",
    "\n",
    "            ### filling factor\n",
    "            # calculate filling factor\n",
    "            f_bright, f_spot, f = sfuncs.filling_factor(mu, mmap, active, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### unsigned magnetic flux\n",
    "            # unsigned observed flux\n",
    "            unsigned_obs_flux = sfuncs.unsigned_flux(map_mag_obs, imap)\n",
    "\n",
    "            ### calculate the area filling factor\n",
    "            pixA_hem = ctfuncs.pix_area_hem(wij, nij, rij, vmap)\n",
    "            area = sfuncs.area_calc(active, pixA_hem)\n",
    "            f_small, f_large, f_network, f_plage = sfuncs.area_filling_factor(active, area, mu, mmap, fac_inds,\n",
    "                                                                              athresh=Parameters.athresh,\n",
    "                                                                              mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### get the unsigned flux\n",
    "            quiet_flux, ar_flux, conv_flux, pol_flux, pol_conv_flux = sfuncs.area_unsigned_flux(map_mag_obs, imap,\n",
    "                                                                                                    area,\n",
    "                                                                                                    active,\n",
    "                                                                                                athresh=Parameters.athresh)\n",
    "\n",
    "            ### get area weighted convective velocities\n",
    "            vconv_quiet, vconv_large, vconv_small = sfuncs.area_vconv(map_vel_cor, imap, active, area, athresh=Parameters.athresh)\n",
    "            ### calculate model RV\n",
    "            rv_model = rvs.calc_model(Inputs.inst, v_conv, v_phot)\n",
    "\n",
    "            # intensity flux to check\n",
    "            int_flux = np.nansum(imap.data)\n",
    "            \n",
    "            # make array of what we want to save\n",
    "            save_vals = [rv_model, v_quiet, v_disc, v_phot, v_conv, f_bright, f_spot, f, unsigned_obs_flux, vphot_bright,\n",
    "                         vphot_spot, f_small, f_large, f_network, f_plage, quiet_flux, ar_flux,\n",
    "                         conv_flux, pol_flux, pol_conv_flux, vconv_quiet, vconv_large, vconv_small, int_flux]\n",
    "\n",
    "            # round stuff\n",
    "            rounded = np.around(save_vals, 3)\n",
    "            round_vals = [date_str, date_jd]\n",
    "            for val in rounded:\n",
    "                round_vals.append(val)\n",
    "\n",
    "            # append these values to the csv file\n",
    "            utils.append_list_as_row(csv_file, round_vals)\n",
    "\n",
    "            # print that the date is completed\n",
    "            print('\\nCalculations and save to file complete for ' + date_str + ' index: ' + str(i))\n",
    "\n",
    "print('Calculation complete for dates:', start_date, 'to', end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# csv file with rv components\n",
    "csv_file = os.path.join(CsvDir.CALC, Inputs.csv_name)\n",
    "\n",
    "# create pandas dataframe\n",
    "component_df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# date to plot\n",
    "date_jd = component_df.date_jd.values\n",
    "x = date_jd - date_jd[0]\n",
    "y_list = [component_df.f.values, component_df.Bobs.values, component_df.v_conv.values, component_df.v_phot.values,\n",
    "          component_df.rv_model.values - np.median(component_df.rv_model.values)]\n",
    "\n",
    "# plot labels\n",
    "xlabel = 'Days since ' + str(int(date_jd[0])) + ' JD'\n",
    "ylabel_list = [r'$\\rm f$' '\\n' r'$\\rm$[%]',\n",
    "               r'$\\rm B_{\\rm obs}$' '\\n' r'$\\rm [G]$',\n",
    "               r'$\\rm v_{\\rm conv}$' '\\n' r'$\\rm[m s^{-1}]$',\n",
    "               r'$\\rm v_{\\rm phot}$' '\\n' r'$\\rm[m s^{-1}]$',\n",
    "               r'$\\rm RV_{\\rm model}$' '\\n' r'$\\rm[m s^{-1}]$']\n",
    "\n",
    "# set up figure\n",
    "fig, axs = plt.subplots(len(y_list), 1, sharex='all', figsize=[6, 1.5 * len(y_list)],  gridspec_kw={'hspace': 0})\n",
    "\n",
    "# set up axes labels\n",
    "for i in range(0, len(axs)):\n",
    "    axs[i].set(ylabel=ylabel_list[i])\n",
    "    rng = (y_list[i].max() - y_list[i].min())\n",
    "    step = rng/6\n",
    "    ylim = (y_list[i].min() - step, y_list[i].max() + step)\n",
    "    yticks = np.arange(y_list[i].min(), y_list[i].max()+0.0002, step=step*2)\n",
    "    axs[i].set(ylim=ylim, yticks=yticks)\n",
    "\n",
    "# create x-axis ticks and labels\n",
    "axs[i].set(xlabel=xlabel)\n",
    "rng = (x.max() - x.min())\n",
    "step = rng/6\n",
    "xlim = (x.min() - step, x.max() + step)\n",
    "xticks = np.arange(x.min(), x.max()+.001, step=step*2)\n",
    "axs[i].set(xlim=xlim, xticks=xticks)\n",
    "\n",
    "# plot data\n",
    "for i in range(0, len(axs)):\n",
    "    axs[i].scatter(x, y_list[i], color='thistle', s=30, edgecolors='k', linewidths=0.8,\n",
    "                   label='rms: ' + str(np.round(np.std(y_list[i]), 3)))\n",
    "\n",
    "    leg = axs[i].legend(handlelength=0, handletextpad=0, loc='upper left')\n",
    "    for item in leg.legendHandles:\n",
    "        item.set_visible(False)\n",
    "\n",
    "\n",
    "# align y axis labels\n",
    "fig.align_ylabels(axs)\n",
    "\n",
    "# save figure\n",
    "fig_path = os.path.join(ImgDir.IMG_DIR, 'example_rv_comp.png')\n",
    "fig.savefig(fig_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
